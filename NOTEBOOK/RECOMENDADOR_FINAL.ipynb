{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d3ddc54-d3b6-4ead-9e53-688699e916e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d3ddc54-d3b6-4ead-9e53-688699e916e6",
        "outputId": "067fc482-19f7-4ea0-ee30-d57fb5784f56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: snowflake-connector-python[pandas] in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.16.0)\n",
            "Requirement already satisfied: snowflake-snowpark-python in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.35.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.7.1)\n",
            "Requirement already satisfied: selenium in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.35.0)\n",
            "Requirement already satisfied: nltk in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
            "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (1.5.1)\n",
            "Requirement already satisfied: boto3>=1.24 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (1.40.1)\n",
            "Requirement already satisfied: botocore>=1.24 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (1.40.1)\n",
            "Requirement already satisfied: cffi<2.0.0,>=1.9 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (1.17.1)\n",
            "Requirement already satisfied: cryptography>=3.1.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (45.0.5)\n",
            "Requirement already satisfied: pyOpenSSL<26.0.0,>=22.0.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (25.1.0)\n",
            "Requirement already satisfied: pyjwt<3.0.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2.10.1)\n",
            "Requirement already satisfied: pytz in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2025.2)\n",
            "Requirement already satisfied: requests<3.0.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2.32.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions<5,>=4.3 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (4.14.1)\n",
            "Requirement already satisfied: filelock<4,>=3.5 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (3.18.0)\n",
            "Requirement already satisfied: sortedcontainers>=2.4.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2.4.0)\n",
            "Requirement already satisfied: platformdirs<5.0.0,>=2.6.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (4.3.8)\n",
            "Requirement already satisfied: tomlkit in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (0.13.3)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (2.3.1)\n",
            "Requirement already satisfied: pyarrow<19.0.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-connector-python[pandas]) (18.1.0)\n",
            "Requirement already satisfied: setuptools>=40.6.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (80.9.0)\n",
            "Requirement already satisfied: wheel in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (0.45.1)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (6.0.2)\n",
            "Requirement already satisfied: cloudpickle!=2.1.0,!=2.2.0,<=3.0.0,>=1.6.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (3.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (2.9.0.post0)\n",
            "Requirement already satisfied: tzlocal in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from snowflake-snowpark-python) (5.3.1)\n",
            "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: urllib3[socks]<3.0,>=2.5.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: click in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2025.7.34)\n",
            "Requirement already satisfied: tqdm in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3>=1.24->snowflake-connector-python[pandas]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3>=1.24->snowflake-connector-python[pandas]) (0.13.1)\n",
            "Requirement already satisfied: pycparser in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python[pandas]) (2.22)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0.0,>=2.1.2->snowflake-connector-python[pandas]) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil->snowflake-snowpark-python) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: outcome in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\juanpablocarbonellla\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 25.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install \"snowflake-connector-python[pandas]\" snowflake-snowpark-python scikit-learn selenium nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c831848d-43a2-4160-9e86-14b2893522b3",
      "metadata": {
        "id": "c831848d-43a2-4160-9e86-14b2893522b3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import streamlit as st # Nueva importación para la app Streamlit\n",
        "from snowflake.snowpark import Session\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import unicodedata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d7a1d483-1a1b-4c7f-b290-c38eb5baaccd",
      "metadata": {
        "id": "d7a1d483-1a1b-4c7f-b290-c38eb5baaccd"
      },
      "outputs": [],
      "source": [
        "SNOWFLAKE_CONFIG = {\n",
        "    \"account\":  os.getenv(\"SNOWFLAKE_ACCOUNT\", \"FPSYQCG-JS43936\"),\n",
        "    \"user\":     os.getenv(\"SNOWFLAKE_USER\", \"ARONDON\"),\n",
        "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\", \"ZDj3qMyj9xaEM6J\"),  # ⚠️ mueve esto a variables de entorno\n",
        "    \"role\":     os.getenv(\"SNOWFLAKE_ROLE\", \"readonly\"),\n",
        "    \"warehouse\": os.getenv(\"SNOWFLAKE_WH\", \"compute_wh\"),\n",
        "    \"database\":  os.getenv(\"SNOWFLAKE_DB\", \"TUI_TFM\"),\n",
        "    \"schema\":    os.getenv(\"SNOWFLAKE_SCHEMA\", \"PROCESSED\"),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f2dda70b-5a76-4ada-90bb-fef35d14fa77",
      "metadata": {
        "id": "f2dda70b-5a76-4ada-90bb-fef35d14fa77"
      },
      "outputs": [],
      "source": [
        "def load_data_from_snowflake():\n",
        "    \"\"\"Abre sesión, descarga tablas necesarias y cierra la sesión.\"\"\"\n",
        "    try:\n",
        "        with Session.builder.configs(SNOWFLAKE_CONFIG).create() as sf_session:\n",
        "            print(\"✅ Conectado a Snowflake\")\n",
        "            master_forecasted_df = sf_session.table(\"TUI_TFM.PROCESSED.MASTER_FORECASTED\").to_pandas()\n",
        "            experiencis_df = sf_session.table(\"TUI_TFM.PROCESSED.EXP_TUI\").to_pandas()\n",
        "\n",
        "            return experiencis_df, master_forecasted_df\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(f\"❌ Error al cargar desde Snowflake: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "fb08f1e5",
      "metadata": {
        "id": "fb08f1e5"
      },
      "outputs": [],
      "source": [
        "# =========================\n",
        "# Helpers\n",
        "# =========================\n",
        "\n",
        "def ask(msg, default=None, cast=str, valid=None):\n",
        "    while True:\n",
        "        val = input(f\"{msg} [{default}]: \").strip().lower() or str(default).lower()\n",
        "        try:\n",
        "            val = cast(val)\n",
        "        except Exception:\n",
        "            print(\"⚠️ Entrada no válida.\")\n",
        "            continue\n",
        "        if valid and not valid(val):\n",
        "            print(\"⚠️ Valor fuera de rango o no permitido.\")\n",
        "            continue\n",
        "        return val\n",
        "    \n",
        "\n",
        "def normalize(text: str) -> str:\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize(\"NFD\", text)\n",
        "        if unicodedata.category(c) != \"Mn\"\n",
        "    ).lower().strip()  \n",
        "\n",
        "def validar_provincia(raw_input: str, df_provincias: pd.Series) -> str:\n",
        "\n",
        "    PROV_ALIASES = {\n",
        "        \"las palmas\": \"Palmas, Las\",\n",
        "        \"palmas\": \"Palmas, Las\",\n",
        "        \"coruna\": \"Coruña, A\",\n",
        "        \"a coruna\": \"Coruña, A\",\n",
        "        \"la coruna\": \"Coruña, A\",\n",
        "        \"baleares\": \"Balears, Illes\",\n",
        "        \"balears\": \"Balears, Illes\",\n",
        "        \"islas baleares\": \"Balears, Illes\",\n",
        "        \"illes balears\": \"Balears, Illes\",\n",
        "        \"la rioja\": \"Rioja, La\",\n",
        "        \"rioja\": \"Rioja, La\",\n",
        "    }\n",
        "\n",
        "    norm_input = normalize(raw_input)\n",
        "\n",
        "    # Primero intentamos con aliases\n",
        "    if norm_input in PROV_ALIASES:\n",
        "        return PROV_ALIASES[norm_input].lower()\n",
        "\n",
        "    # Si no está en aliases, buscamos entre las provincias del DataFrame\n",
        "    prov_map = {normalize(p): p for p in df_provincias.unique()}\n",
        "    if norm_input in prov_map:\n",
        "        return prov_map[norm_input].lower()\n",
        "\n",
        "    # Finalmente, buscamos coincidencias parciales: si el input está contenido en algún nombre\n",
        "    for norm_name, official_name in prov_map.items():\n",
        "        if norm_input in norm_name:  # coincidencia parcial\n",
        "            return official_name.lower()\n",
        "\n",
        "    raise ValueError(f\"Provincia '{raw_input}' no encontrada\")\n",
        "\n",
        "def norm_0_1(series: pd.Series) -> pd.Series:\n",
        "    \"\"\"Normaliza una serie a [0,1] de forma segura.\"\"\"\n",
        "    s = series.astype(float)\n",
        "    return (s - s.min()) / (s.max() - s.min()) if s.max() > s.min() else 0 * s\n",
        "\n",
        "def normalize_columns(df: pd.DataFrame, cols: list[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Normaliza las columnas indicadas del DataFrame usando norm_0_1.\n",
        "    Devuelve un DataFrame con las columnas normalizadas, renombradas con '_index'.\n",
        "    \"\"\"\n",
        "    df_norm = pd.DataFrame(index=df.index)  # Nuevo DF solo con índices\n",
        "    for c in cols:\n",
        "        if c in df.columns:\n",
        "            df_norm[f\"{c}_index\"] = norm_0_1(df[c])\n",
        "    return df_norm\n",
        "\n",
        "def _geo_accept_set(t: str) -> set:\n",
        "\n",
        "    if t == \"playa\":\n",
        "        return {\"playa\", \"mixto\"}\n",
        "    if t == \"montaña\":\n",
        "        return {\"montana\", \"mixto\"}\n",
        "    if t == \"urbano\":\n",
        "        return {\"urbano\"}                      # mixto NO vale para urbano\n",
        "    if t == \"mixto\":\n",
        "        return {\"playa\", \"montana\", \"mixto\"}   # mixto = playa+montaña\n",
        "    return set()\n",
        "\n",
        "def _geo_mask(series_geo: pd.Series, tourism: str) -> pd.Series:\n",
        "    accept = _geo_accept_set(tourism)\n",
        "    if not accept:\n",
        "        return pd.Series(True, index=series_geo.index)\n",
        "    return series_geo.isin(accept)\n",
        "\n",
        "def categorize(value, series):\n",
        "    p25, p75 = series.quantile([0.25, 0.75])\n",
        "    if value <= p25:\n",
        "        return \"low\"\n",
        "    elif value <= p75:\n",
        "        return \"medium\"\n",
        "    else:\n",
        "        return \"high\"\n",
        "    \n",
        "def _alts_once(df_slice, base_row, sim_matrix, tourism_type, sim_geo_bonus, \n",
        "               top_set, target_temp, crowd_delta, temp_dev, user_drop, require_geo=True):\n",
        "\n",
        "    pos = {p: i for i, p in enumerate(df_slice[\"province\"].tolist())}        \n",
        "    i = pos[base_row[\"province\"]]\n",
        "    candidates = df_slice.copy()\n",
        "    sim_base = sim_matrix[i]\n",
        "    \n",
        "    # bonus similitud por geografía alineada\n",
        "    if tourism_type:\n",
        "        cg = candidates[\"geography\"]\n",
        "        geo_accept = _geo_accept_set(tourism_type)  # devuelve el set de geografía aceptable\n",
        "        geo_ok = cg.isin(geo_accept)\n",
        "        sim_adj = sim_base + sim_geo_bonus * geo_ok.astype(float).values\n",
        "    else:\n",
        "        sim_adj = sim_base\n",
        "        geo_ok = pd.Series(True, index=candidates.index)\n",
        "\n",
        "    mask = (\n",
        "        (~candidates[\"province\"].isin(top_set)) &\n",
        "        (candidates[\"crowd_index\"] < base_row[\"crowd_index\"] - float(crowd_delta)) &\n",
        "        (candidates[\"user_score\"] >= base_row[\"user_score\"] * (1.0 - float(user_drop))) &\n",
        "        ((candidates[\"mean_temp\"] - float(target_temp)).abs() <= float(temp_dev))\n",
        "    )\n",
        "\n",
        "    if require_geo:\n",
        "        mask = mask & geo_ok\n",
        "\n",
        "    cand = candidates[mask].copy()\n",
        "    if cand.empty:\n",
        "        return cand\n",
        "    cand[\"similarity\"] = sim_adj[mask]\n",
        "    return cand.nlargest(3, \"similarity\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e20f2e41-275a-41e7-8af4-b0035fecb942",
      "metadata": {
        "id": "e20f2e41-275a-41e7-8af4-b0035fecb942"
      },
      "outputs": [],
      "source": [
        "def build_province_month_features(raw_df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Renombra columnas a un estándar, extrae mes, construye eventos y\n",
        "    genera índices normalizados por mes (demanda/precio/crowd).\n",
        "    \"\"\"\n",
        "    column_map = {\n",
        "        \"NOMBRE_CCAA\": \"ccaa\",                           # si existe\n",
        "        \"NOMBRE_PRO\": \"province\", \"PERIODO\": \"period\",\n",
        "        \"TEMP_MED\": \"mean_temp\", \"TEMP_MAX\": \"max_temp\", \"TEMP_MIN\": \"min_temp\",\n",
        "        \"PRECIPITACION\": \"rain\", \"ADR\": \"price\",\n",
        "        \"PROPORCION_OCUPACION_HABIT\": \"crowd\",\n",
        "        \"PROPORCION_OCUPACION_CAMAS\": \"occ_beds\",\n",
        "        \"PROPORCION_OCUPACION_CAMAS_FINDE\": \"occ_beds_weekend\",\n",
        "        \"ESTABLECIMIENTOS_ABIERTOS\": \"establishments\",\n",
        "        \"NUMERO_DE_HABITACIONES\": \"n_rooms\", \"NUMERO_DE_CAMAS\": \"n_beds\",\n",
        "        \"EMPLEADOS\": \"employees\", \"TURISTAS\": \"tourists\",\n",
        "        \"ALTITUD\": \"altitude\",\n",
        "        \"GEOGRAFIA\": \"geography\",\n",
        "    }\n",
        "    df = raw_df.rename(columns=column_map).copy()\n",
        "\n",
        "    # Formato YYYY-MM -> Period(M)\n",
        "    df[\"period_str\"] = df[\"period\"].astype(str).str.replace(\"M\", \"-\") \n",
        "    df[\"year_month\"] = pd.to_datetime(df[\"period_str\"], format=\"%Y-%m\", errors=\"coerce\").dt.to_period(\"M\")\n",
        "\n",
        "    df[\"geography\"] = df[\"geography\"].str.lower()\n",
        "\n",
        "    # Total de eventos\n",
        "    event_cols = [\"HOBBIES_AND_GAMES\", \"ARTS_AND_SOCIETY\", \"SPORTS_AND_WELLNESS\", \"FESTIVALS\", \"FOOD\", \"FAMILY\"]\n",
        "    df[\"events_total\"] = df[event_cols].sum(axis=1)\n",
        "\n",
        "    feature_cols = [\n",
        "        \"province\", \"year_month\",\n",
        "        \"mean_temp\", \"max_temp\", \"min_temp\", \"rain\",\n",
        "        \"events_total\", *event_cols, \"price\", \"crowd\",\n",
        "        \"establishments\", \"n_rooms\", \"n_beds\", \"employees\", \"tourists\",\n",
        "        \"altitude\", \"geography\",\n",
        "    ]\n",
        "    features_df = df[feature_cols].dropna(subset=[\"province\", \"year_month\"])\n",
        "    numeric_cols = features_df.select_dtypes(include=np.number).columns.tolist()\n",
        "    features_df_norm = normalize_columns(features_df, numeric_cols)\n",
        "    features_df = pd.concat([features_df, features_df_norm], axis=1)\n",
        "\n",
        "    return features_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "6d7299c0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def recomendar_alternativas(\n",
        "    features_df: pd.DataFrame, \n",
        "    modo: str,\n",
        "    top_n: int = 3,\n",
        "    min_crowd_delta: float = 0.25,\n",
        "    max_user_score_drop: float = 0.15,\n",
        "    max_temp_deviation_c: float = 3.0,\n",
        "    sim_geo_bonus: float = 0.08,\n",
        "    ensure_alternatives: bool = True,    # último recurso si no hay alts\n",
        ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Recomienda alternativas de provincias.\n",
        "    \"\"\"\n",
        "        # --- Inputs básicos ---\n",
        "    if modo == \"2\":\n",
        "        raw_input = ask(\"Provincia base (ej: Madrid): \", \"Madrid\", str).lower()\n",
        "        provincia_base = validar_provincia(raw_input, features_df[\"province\"])\n",
        "\n",
        "        \n",
        "    mes = ask(\"Mes de viaje (01-12): \", \"07\", int, lambda x: 1 <= x <= 12)\n",
        "    anio = ask(\"Año de viaje (2025-2026): \", \"2025\", int, lambda x: 2025 <= x <= 2026)\n",
        "    period = pd.Period(f\"{anio}-{mes}\", freq=\"M\")\n",
        "    \n",
        "\n",
        "\n",
        "    preference = ask(\"¿Tienes preferencia por algún tipo de evento? (s/n): \", \"n\", str, lambda x: x in (\"s\",\"n\"))\n",
        "    \n",
        "        # --- Slice de periodo ---\n",
        "    df_slice = features_df[features_df[\"year_month\"] == period].copy()\n",
        "    complete_slice_df = df_slice.copy()\n",
        "\n",
        "    if df_slice.empty:\n",
        "        raise ValueError(f\"No hay datos para {period}\")\n",
        "\n",
        "        # --- Selección de eventos ---\n",
        "    event_weights = {}\n",
        "    selected_events = []\n",
        "    if preference == \"s\":\n",
        "        available_event_cols = [\"HOBBIES AND GAMES\",\"ARTS AND SOCIETY\",\"SPORTS AND WELLNESS\",\n",
        "                                \"FESTIVALS\",\"FOOD\",\"FAMILY\"]\n",
        "        for i,c in enumerate(available_event_cols,1):\n",
        "            print(f\"{i}. {c.capitalize()}\")\n",
        "        while True:\n",
        "            selection = ask(\"Selecciona hasta 3 eventos por número (ej:1,2,3): \",\"\")\n",
        "            try:\n",
        "                idx = [int(x)-1 for x in selection.split(\",\") if x.strip()]\n",
        "                if not idx or len(idx)>3 or any(i<0 or i>=len(available_event_cols) for i in idx):\n",
        "                    print(\"⚠️ Entrada inválida.\")\n",
        "                    continue\n",
        "                break\n",
        "            except: print(\"⚠️ Entrada no válida.\")\n",
        "        selected_events = [available_event_cols[i] for i in idx]\n",
        "        weights_base = np.linspace(1.0,0.5,len(selected_events))\n",
        "        weights = weights_base / weights_base.sum()\n",
        "        event_weights = {c:w for c,w in zip(selected_events,weights)}\n",
        "    else:\n",
        "        event_weights = {\"events_total\":1.0}\n",
        "\n",
        "    # --- Provincia base y tolerancias ---\n",
        "    if modo == \"2\":\n",
        "\n",
        "        prov_map = {p.lower(): p for p in df_slice[\"province\"].unique()}\n",
        "        if provincia_base not in prov_map:\n",
        "            raise ValueError(f\"Provincia '{provincia_base}' no encontrada\")\n",
        "        \n",
        "        prov_key = prov_map[provincia_base]\n",
        "        base_row = df_slice[df_slice[\"province\"] == prov_key].iloc[0]\n",
        "\n",
        "        tourism_type = base_row[\"geography\"]\n",
        "        target_temp = base_row[\"mean_temp\"]\n",
        "        crowd = categorize(base_row[\"crowd_index\"], df_slice[\"crowd_index\"])\n",
        "        rain = categorize(base_row[\"rain_index\"], df_slice[\"rain_index\"])\n",
        "        budget = categorize(base_row[\"price_index\"], df_slice[\"price_index\"])\n",
        "\n",
        "        if tourism_type in (\"playa\",\"montaña\",\"urbano\",\"mixto\"):\n",
        "            mask_geo = _geo_mask(df_slice[\"geography\"], tourism_type)\n",
        "            df_slice = df_slice[mask_geo]\n",
        "            if df_slice.empty:\n",
        "                print(\"EMPTY do to tourism_type\")\n",
        "                return pd.DataFrame(), pd.DataFrame(), []\n",
        "\n",
        "    else:\n",
        "        \n",
        "        tourism_type = ask(\"Tipo de turismo (playa/montaña/urbano/mixto/n): \", \"n\",\n",
        "            str, lambda x: x.lower() in (\"playa\",\"montaña\",\"urbano\",\"mixto\",\"n\",\"\"))\n",
        "        \n",
        "        if tourism_type in (\"playa\",\"montaña\",\"urbano\",\"mixto\"):\n",
        "            mask_geo = _geo_mask(df_slice[\"geography\"], tourism_type)\n",
        "            df_slice = df_slice[mask_geo]\n",
        "            if df_slice.empty:\n",
        "                print(\"EMPTY do to tourism_type\")\n",
        "                return pd.DataFrame(), pd.DataFrame(), []\n",
        "\n",
        "\n",
        "        temp_min = round(df_slice[\"mean_temp\"].min())\n",
        "        temp_max = round(df_slice[\"mean_temp\"].max())\n",
        "\n",
        "        target_temp = ask(\n",
        "            f\"Temperatura deseada ({temp_min}-{temp_max}): \",\n",
        "            str((temp_min + temp_max) // 2), \n",
        "            int,\n",
        "            lambda x: temp_min <= x <= temp_max\n",
        "        )\n",
        "        \n",
        "        crowd = ask(\"Tolerancia a multitudes (low/medium/high): \",\"medium\",str, lambda x: x in (\"low\",\"medium\",\"high\"))\n",
        "        rain   = ask(\"Tolerancia lluvia (low/medium/high): \",\"medium\",str, lambda x: x in (\"low\",\"medium\",\"high\"))\n",
        "        budget = ask(\"Presupuesto (low/medium/high): \",\"medium\",str, lambda x: x in (\"low\",\"medium\",\"high\"))\n",
        "\n",
        "        # --- Filtrado geográfico estricto ---\n",
        "        \n",
        "            # --- Gate de temperatura ---\n",
        "    df_slice = df_slice[(df_slice[\"mean_temp\"] - target_temp).abs() <= 4.0]\n",
        "\n",
        "    if df_slice.empty:\n",
        "        print(\"EMPTY do to temperature\")\n",
        "        return pd.DataFrame(), pd.DataFrame(), []\n",
        "\n",
        "        # --- User score ---\n",
        "    event_signal = sum(df_slice.get(ev, pd.Series(0, index=df_slice.index)) * w\n",
        "                        for ev, w in event_weights.items())\n",
        "\n",
        "    offer_cols = [\"establishments\", \"n_beds\", \"employees\"]\n",
        "\n",
        "    event_index = norm_0_1(np.log1p(event_signal.astype(float)))\n",
        "    temp_score = np.exp(-((df_slice[\"mean_temp\"] - float(target_temp)).abs() / 4.0))\n",
        "    offer_score = norm_0_1(df_slice[offer_cols].sum(axis=1))\n",
        "\n",
        "    crowd_penalty = (1 - df_slice[\"crowd_index\"])\n",
        "    price_penalty = (1 - df_slice[\"price_index\"])\n",
        "    rain_penalty  = (1 - df_slice[\"rain_index\"])\n",
        "\n",
        "    tol_weights = {\n",
        "        \"crowd\":{\"low\":0.5,\"medium\":0.30,\"high\":0}.get(crowd,0.30),\n",
        "        \"rain\":{\"low\":0.5,\"medium\":0.30,\"high\":0}.get(rain,0.30),\n",
        "        \"price\":{\"low\":0.5,\"medium\":0.30,\"high\":0.1}.get(budget,0.30)\n",
        "        }\n",
        "    \n",
        "    tol_comp = (\n",
        "        tol_weights[\"crowd\"] * crowd_penalty +\n",
        "        tol_weights[\"price\"] * price_penalty +\n",
        "        tol_weights[\"rain\"]  * rain_penalty\n",
        "    )\n",
        "\n",
        "    base_user_score = (\n",
        "        0.30 * temp_score +\n",
        "        0.25 * event_index +\n",
        "        0.25 * tol_comp +\n",
        "        0.20 * offer_score\n",
        "    )\n",
        "\n",
        "    df_slice[\"user_score\"] = base_user_score\n",
        "    complete_slice_df[\"user_score\"] = base_user_score\n",
        "\n",
        "        # --- Top base ---\n",
        "    if modo == \"2\":\n",
        "        top_base = df_slice[df_slice[\"province\"]==prov_key]\n",
        "        top_set = {prov_key}\n",
        "    else:\n",
        "        top_base = df_slice.nlargest(top_n,\"user_score\")\n",
        "        top_set = set(top_base[\"province\"])\n",
        "\n",
        "    columns_to_keep = [c for c in top_base.columns if c.endswith(\"_index\")]\n",
        "    alt_blocks = []\n",
        "\n",
        "    # Definimos los intentos de relajación como tuplas de parámetros\n",
        "    relaxations = [\n",
        "        (min_crowd_delta, max_temp_deviation_c, max_user_score_drop, True),        # Estricto\n",
        "        (min_crowd_delta*0.75, max_temp_deviation_c+1, max_user_score_drop+0.05, True),    # Relajación 1\n",
        "        (min_crowd_delta*0.5, max_temp_deviation_c+2, max_user_score_drop+0.10, True)  # Relajación 2\n",
        "    ]\n",
        "\n",
        "    for _, base in top_base.iterrows():\n",
        "        cand = pd.DataFrame()\n",
        "        \n",
        "        # Intentos progresivos\n",
        "        for crowd_delta, temp_dev, user_drop, require_geo in relaxations:\n",
        "\n",
        "            M = df_slice[columns_to_keep].copy().to_numpy()\n",
        "            sim_matrix = cosine_similarity(np.nan_to_num(M, nan=0.0, posinf=0.0, neginf=0.0))\n",
        "\n",
        "            cand = _alts_once(\n",
        "                df_slice, base, sim_matrix, tourism_type, sim_geo_bonus, \n",
        "                top_set, target_temp, crowd_delta, temp_dev, user_drop, require_geo\n",
        "            )\n",
        "\n",
        "            cand = cand[~cand[\"province\"].isin(top_set)]\n",
        "\n",
        "            if not cand.empty:\n",
        "                break\n",
        "        \n",
        "        # Último recurso si ensure_alternatives=True\n",
        "        if (cand.empty or len(cand) < top_n) and ensure_alternatives:\n",
        "            # Inicializamos parámetros relajados\n",
        "            crowd_relax = 0.25\n",
        "            temp_relax = 3\n",
        "            user_drop_relax = 0.15\n",
        "            step = 0.05  # incremento gradual de user_drop\n",
        "            max_iter = 20  # evitar bucles infinitos\n",
        "\n",
        "            M = complete_slice_df[columns_to_keep].copy().to_numpy()\n",
        "            sim_matrix = cosine_similarity(np.nan_to_num(M, nan=0.0, posinf=0.0, neginf=0.0))\n",
        "\n",
        "            for _ in range(max_iter):\n",
        "\n",
        "                cand = _alts_once(\n",
        "                    complete_slice_df, base, sim_matrix, tourism_type, sim_geo_bonus, \n",
        "                    top_set, target_temp, crowd_relax, temp_relax, user_drop_relax, require_geo=False\n",
        "                )\n",
        "\n",
        "                cand = cand[~cand[\"province\"].isin(top_set)]\n",
        "\n",
        "                if not cand.empty and len(cand) >= top_n:\n",
        "                    cand[\"note\"] = \"(relaxed)\"\n",
        "                    break\n",
        "\n",
        "                # Relajamos progresivamente los parámetros\n",
        "                crowd_relax *= 0.9\n",
        "                temp_relax += 1\n",
        "                user_drop_relax += step\n",
        "        \n",
        "        if not cand.empty:\n",
        "            alt_blocks.append(cand)\n",
        "\n",
        "    # Concatenamos y limitamos a max_alternatives\n",
        "    if alt_blocks:\n",
        "        alternatives = pd.concat(alt_blocks, ignore_index=True).drop_duplicates(\"province\")\n",
        "        alternatives = alternatives.sort_values(\"similarity\", ascending=False).head(top_n).reset_index(drop=True)\n",
        "    else:\n",
        "        alternatives = pd.DataFrame()\n",
        "\n",
        "    # --- Return según modo ---\n",
        "    if modo == \"2\":\n",
        "        # Modo provincia base\n",
        "        if alternatives.empty:\n",
        "            print(\"\\n(No hay alternativas suficientemente similares a la provincia base.)\")\n",
        "            return prov_key, None, selected_events  # devolvemos None en alternativas\n",
        "        else:\n",
        "            print(\"\\n=== Alternativas menos masificadas ===\")\n",
        "            for r in alternatives[\"province\"]:\n",
        "                print(f\"- {r}\")\n",
        "            \n",
        "        return prov_key, alternatives, selected_events\n",
        "    \n",
        "    else:\n",
        "        \n",
        "        # Modo top destinos\n",
        "        if top_base.empty:\n",
        "            print(\"⚠️ No hay resultados para ese mes.\")\n",
        "            return None, None, selected_events  # devolvemos None en todo\n",
        "        else:\n",
        "            print(\"\\n=== Top destinos por tus gustos ===\")\n",
        "            for _, r in top_base.iterrows():\n",
        "                print(f\"- {r['province']}\")\n",
        "\n",
        "        if alternatives.empty:\n",
        "            print(\"\\n(No hay alternativas menos masificadas suficientemente similares.)\")\n",
        "            return top_base, None, selected_events\n",
        "        else:\n",
        "            print(\"\\n=== Alternativas menos masificadas ===\")\n",
        "            for r in alternatives[\"province\"]:\n",
        "                print(f\"- {r}\")\n",
        "\n",
        "            return top_base, alternatives, selected_events\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5c0720e0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def recomendar_actividades(df, provincia, categorias=None, top_n=3):\n",
        "    df_filtrado = df[df[\"NOMBRE_PRO\"].str.lower() == provincia.lower()].copy()\n",
        "\n",
        "    # Filtrar por categorías si el usuario especifica\n",
        "    if categorias:\n",
        "        categorias = [c.lower() for c in categorias]\n",
        "        df_filtrado = df_filtrado[\n",
        "            df_filtrado[\"CATEGORIAS\"].apply(\n",
        "                lambda x: any(cat in x.lower() for cat in categorias)\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    # Calcular promedio global\n",
        "    C = df[\"RATING\"].mean()\n",
        "\n",
        "    # Calcular weighted rating SOLO si hay reviews\n",
        "    def calcular_score(row):\n",
        "        if row[\"REVIEWS_COUNT\"] == 0 or pd.isna(row[\"RATING\"]):\n",
        "            return -1  # penalización dura\n",
        "        v = row[\"REVIEWS_COUNT\"]\n",
        "        R = row[\"RATING\"]\n",
        "        return (v / (v + 50)) * R + (50 / (v + 50)) * C  # fórmula IMDB\n",
        "\n",
        "    df_filtrado[\"score\"] = df_filtrado.apply(calcular_score, axis=1)\n",
        "\n",
        "    # Ordenar por score y seleccionar top_n\n",
        "    recomendadas = df_filtrado.sort_values(\"score\", ascending=False).head(top_n)\n",
        "\n",
        "    return recomendadas[[\"NOMBRE_PRO\", \"TITULO\", \"RATING\", \"REVIEWS_COUNT\",\"score\",\"LINK\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "b805c9b0",
      "metadata": {},
      "outputs": [],
      "source": [
        "def unificado(df_actividades, features_df, top_n_actividades=3):\n",
        "\n",
        "    print(\"\\n¡Bienvenido al sistema de recomendaciones de viajes!\\n\")\n",
        "    print(\"1) Recomendación automática: te sugerimos destinos según tus preferencias.\")\n",
        "    print(\"2) Selección de provincia base: tú eliges una provincia y mostramos similares.\\n\")\n",
        "\n",
        "    while (modo := input(\"Ingresa 1 o 2 según el modo que deseas usar: \").strip()) not in (\"1\", \"2\"):\n",
        "        print(\"⚠️ Entrada no válida. Por favor ingresa 1 o 2.\")\n",
        "\n",
        "    print(f\"\\nHas elegido {'la recomendación automática' if modo=='1' else 'la selección de provincia base'}.\\n\")\n",
        "\n",
        "    result = recomendar_alternativas(features_df, modo)\n",
        "\n",
        "    top_df, provincia_base, alt_df, selected_events = (\n",
        "        (result[0], None, result[1], result[2]) if modo == \"1\"\n",
        "        else (None, result[0], result[1], result[2])\n",
        "    )\n",
        "\n",
        "    top_provincias = top_df[\"province\"].tolist() if top_df is not None else []\n",
        "    alt_provincias = alt_df[\"province\"].tolist() if alt_df is not None else []\n",
        "\n",
        "\n",
        "    def mostrar_actividades(provincias, titulo, skip_base=False):\n",
        "        print(f\"\\n=== {titulo} ===\")\n",
        "        for prov in provincias:\n",
        "            if skip_base and prov == provincia_base:\n",
        "                continue\n",
        "            if prov.upper() not in df_actividades[\"NOMBRE_PRO\"].str.upper().values:\n",
        "                print(f\"\\n⚠️ No hay actividades en {prov}\")\n",
        "                continue\n",
        "            actividades = recomendar_actividades(df_actividades, prov, categorias=selected_events, top_n=top_n_actividades)\n",
        "            if actividades.empty:\n",
        "                print(f\"\\n⚠️ No hay actividades encontradas en {prov}\")\n",
        "            else:\n",
        "                print(f\"\\n--- {prov} ---\")\n",
        "                print(actividades)\n",
        "\n",
        "    if provincia_base:\n",
        "        mostrar_actividades([provincia_base], f\"ACTIVIDADES EN {provincia_base.upper()}\")\n",
        "    else:\n",
        "        mostrar_actividades(top_provincias, \"ACTIVIDADES EN PROVINCIAS PRINCIPALES\")\n",
        "    if alt_df is not None:\n",
        "        mostrar_actividades(alt_provincias, \"ACTIVIDADES EN PROVINCIAS SIMILARES / ALTERNATIVAS\", skip_base=True)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ff0213dc-b09f-4a01-89dc-2a67144f9508",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff0213dc-b09f-4a01-89dc-2a67144f9508",
        "outputId": "28e91f38-d760-4a4d-e10e-4ce2401fe689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Conectado a Snowflake\n",
            "✅ PROVINCE_MONTH listo\n"
          ]
        }
      ],
      "source": [
        "experiencias_df, master_forecasted_df = load_data_from_snowflake()\n",
        "province_month_df = build_province_month_features(master_forecasted_df)\n",
        "print(\"✅ PROVINCE_MONTH listo\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "0ab0a244",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "¡Bienvenido al sistema de recomendaciones de viajes!\n",
            "\n",
            "1) Recomendación automática: te sugerimos destinos según tus preferencias.\n",
            "2) Selección de provincia base: tú eliges una provincia y mostramos similares.\n",
            "\n",
            "\n",
            "Has elegido la selección de provincia base.\n",
            "\n",
            "\n",
            "=== Alternativas menos masificadas ===\n",
            "- Sevilla\n",
            "- Salamanca\n",
            "- Córdoba\n",
            "\n",
            "=== ACTIVIDADES EN MADRID ===\n",
            "\n",
            "--- Madrid ---\n",
            "   NOMBRE_PRO                                             TITULO  RATING  \\\n",
            "1      Madrid          Madrid - Entradas al Parque Warner Madrid     4.7   \n",
            "44     Madrid     Madrid - Entradas a la Playa del Parque Warner     4.8   \n",
            "5      Madrid  Madrid - Entradas al Parque de Atracciones de ...     4.7   \n",
            "\n",
            "    REVIEWS_COUNT     score                                               LINK  \n",
            "1             644  4.685037  https://www.tuimusement.com/es/espana/madrid/p...  \n",
            "44             44  4.636339  https://www.tuimusement.com/es/espana/madrid/p...  \n",
            "5              86  4.623646  https://www.tuimusement.com/es/espana/madrid/p...  \n",
            "\n",
            "=== ACTIVIDADES EN PROVINCIAS SIMILARES / ALTERNATIVAS ===\n",
            "\n",
            "--- Sevilla ---\n",
            "     NOMBRE_PRO                                             TITULO  RATING  \\\n",
            "129     Sevilla  Sevilla - Entradas sin colas y visita guiada a...     4.7   \n",
            "2       Sevilla  Sevilla - Tickets to the Museum of Illusions i...     4.8   \n",
            "1326    Sevilla  Sevilla - 'Flamenco Dreams Show' at Seville Fl...     4.8   \n",
            "\n",
            "      REVIEWS_COUNT     score  \\\n",
            "129              73  4.615576   \n",
            "2                23  4.589259   \n",
            "1326              8  4.534757   \n",
            "\n",
            "                                                   LINK  \n",
            "129   https://www.tuimusement.com/es/espana/sevilla/...  \n",
            "2     https://www.tuimusement.com/es/espana/sevilla/...  \n",
            "1326  https://www.tuimusement.com/es/espana/sevilla/...  \n",
            "\n",
            "--- Salamanca ---\n",
            "     NOMBRE_PRO                                             TITULO  RATING  \\\n",
            "1559  Salamanca  Salamanca - Boleto de entrada al Palacio de Mo...     4.5   \n",
            "1561  Salamanca  Salamanca - Visita guiada en bicicleta por Sal...     NaN   \n",
            "1562  Salamanca  Salamanca - Recorrido a pie por Salamanca de n...     NaN   \n",
            "\n",
            "      REVIEWS_COUNT     score  \\\n",
            "1559              3  4.492753   \n",
            "1561              0 -1.000000   \n",
            "1562              0 -1.000000   \n",
            "\n",
            "                                                   LINK  \n",
            "1559  https://www.tuimusement.com/es/espana/salamanc...  \n",
            "1561  https://www.tuimusement.com/es/espana/salamanc...  \n",
            "1562  https://www.tuimusement.com/es/espana/salamanc...  \n",
            "\n",
            "--- Córdoba ---\n",
            "    NOMBRE_PRO                                             TITULO  RATING  \\\n",
            "47     Córdoba  Córdoba - Visita guiada a la Mezquita Mayor de...     4.7   \n",
            "146    Córdoba        Córdoba - Visita guiada a la Medina Azahara     4.9   \n",
            "79     Córdoba  Córdoba - Visita guiada a la mezquita-catedral...     4.7   \n",
            "\n",
            "     REVIEWS_COUNT     score  \\\n",
            "47             108  4.634278   \n",
            "146             22  4.616887   \n",
            "79              54  4.600153   \n",
            "\n",
            "                                                  LINK  \n",
            "47   https://www.tuimusement.com/es/espana/cordoba/...  \n",
            "146  https://www.tuimusement.com/es/espana/cordoba/...  \n",
            "79   https://www.tuimusement.com/es/espana/cordoba/...  \n"
          ]
        }
      ],
      "source": [
        "unificado(experiencias_df, province_month_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
